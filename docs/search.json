[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "1 Introduction\n\nThis book is a learning diary for CASA0023 Remotely Sensing Cities and Environments\n\n\n\n\nWhat is Remote Sensing"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "2  Week1: Getting started with remote sensing",
    "section": "2.1 Summary",
    "text": "2.1 Summary\n\n2.1.1 The concept of remote sensing\nIn contrast to in situ or on-site observation, remote sensing is the process of gathering data about a phenomenon or object without actually coming into touch with it. The phrase is used particularly in reference to learning more about Earth and other planets.\nThe phrase “remote sensing” today typically refers to the detection and classification of Earthly objects using satellite- or aircraft-based sensor technologies. Based on transmitted signals, it encompasses the atmosphere, the surface, and the oceans (e.g. electromagnetic radiation). It can be divided into “active” and “passive” remote sensing (where a signal is emitted to the object by a satellite or aircraft and its reflection is detected by the sensor) (when the reflection of sunlight is detected by the sensor)\n\n\n\n2.1.2 Piece of work:\nIn the first chapter, I learned how to access remote sensing data using two open source databases, Landsat and Copernicus Open Access Hub, their existence make it easy for me to access remote sensing data from anywhere in the world.\nSecondly, I learned how to use QGIS, SNAP and some packages in R for simple raster processing calculations. I used my own case and followed the instructions step by step, learning a lot about the terminology, gaining some knowledge about remote sensing and statistics and also having some questions."
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "2  Week1: Getting started with remote sensing",
    "section": "2.2 Application",
    "text": "2.2 Application\n\n2.2.1 QGIS\nWhen learning QGIS, I used as an example a map of Zhenjiang and Changzhou, two cities in Jiangsu Province, China, bordered by the Yangtze River to the north, from Copernicus Open Access Hub. Then, merged the B2 (blue), B3 (green), B4 (red) and B8 (NIR) in R10m with multiband colour, and knew the details in different enhancement options. Then, I learned about difference between R10m and R20m. Generally, upsampling is used to complement the situation when the pixel resolution is greater than the source resolution, and a common interpolation method is nearest neighbour, while downsampling is used when pixel resolution is smaller than source resolution. Here is the mechanism of nearest neighbour:\n\\(X_{src}=X_{dst}*\\frac{Width_{src}}{Width_{dst}}\\)\n\\(Y_{src}=Y_{dst}*\\frac{Height_{src}}{Height_{dst}}\\)\nIf the calculation results in a fractional number, then either remove the decimal part or round up to get the same value as the original dotted pixel. This method is very simple but inaccurate, the zoomed in image has a very bad mosaic and the zoomed out image has a very bad distortion. The problem lies in the treatment of the fractional part, which is equivalent to the process of colour gradation and cannot be fully equated with the existing colour of pixel. It is possible to use bilinear interpolation, considering the four values around the point that needs to be scaled, to see which value has more influence on it, and to give it more weight, I saw the option of bilinear interpolation then tried it. In addition, cubic has more accurate result because non-linear function can fit better but more complex.\n\n\n2.2.2 SNAP\nThe sRBG standard colour space can be used for display, network transmission and to convert colour levels on other devices into a colour space that is recognisable to the computer by means of the sRGB conversion function. This is why the brightness levels in the range [0,4095] on the Sentinel-2 can be converted to values in the range [0,255].\nWhen using SNAP, 432 nm means this wavelength is 432 nm, it is a coastal aerosol wave which wavelength is lessmthan blue wave. I like the colour composition function, which allows me to highlight different sections depending on my needs.\n\n\n\nB8-B4-B3\n\n\nHere is the scatter plot of my example:\n\n\n\nscatterplot\n\n\nIt can be seen that map of Zhenjiang and Changzhou has high brightness level, which means it is a city area, and it also shows a lot of wet bare soil, we can assume that these wet soils may be more suitable for cultivation, the overall biomass is not very large and, most notably, there is also a lot of dry bare soil lack of vegetation cover, presumably non-agricultural land.\nWhen using mask function, I got the administrative divisions of these municipalities because I downloaded the administrative divisions of China from GADM data:\n\n\n\nadministrative divisions\n\n\n(yellow: Zhenjiang, pink:Changzhou, red: Taizhou, green:Wuxi, blue: Yangzhou)\nAfter resampling and downscaling the data I got this tasselled plot, compared to the previous one I found that the downscaling had reduced the urban part, so the plot was significantly less bright, and there was more wet bare soil present than the previous one.\n\n\n\nscatterplot\n\n\nGenerally speaking, I prefer using SNAP than QGIS because it has more vivid chart and we can evaluate the local soil conditions, the size of the city and the biomass.\n\n\n2.2.3 R script\nWhen learning the code to deal with data from Landsat and Sentinel, I found a final paired t-test is performed to test whether the actual means of the urban land type from Landsat and Sentinel are equal, the degree of freedom from the results is 5970, p-value is much smaller than 0.05, which means the actual means of two groups are quite different, and at the same time, this calculation also shows the estimate mean of two samples. There are 95% probability that the true mean is between -9300.307 and -9198.368. data from Sentinel and Landsat is different."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "2  Week1: Getting started with remote sensing",
    "section": "2.3 Reflection",
    "text": "2.3 Reflection\nRemote sensing technology is now widely used in scientific research and practice, for land planning, geological exploration and forest fire prevention, so learning to make remote sensing maps is an essential skill.\nThere are several areas of interest to me, one of them is how PCA can be used to reduce the dimensionality of data, particularly in image processing, and I will be doing further study and figuring this out. Then, I would like to know if the image data from satellite remote sensing can be used in AI, as there are already mature deep learning algorithms with a high accuracy rate for image recognition, how to use these images to achieve functions such as automatic recognition and automatic monitoring."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "3  Week2: Portfolio",
    "section": "",
    "text": "Here is the link of presentation which is created via Xaringan: https://GIScodingMo.github.io/week2_xaringan"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "4  Week3: Corrections",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nThis week I learned something about the corrections, the corrections can be divided into four aspects, geometric correction, atmospheric correction, orthorectification correction and radiometric calibration.\n\n4.1.1 Geometric correction\nWhy we need to do the geometric corrections:\n\nThe satellite has view angles when watching the Earth\nThe undulating nature of the terrain (topography)\nWind\nRotation of Earth\n\nThe methods to do the geometric correction:\n\nUse linear regression model to find the relationship between original points and distorted points\nBased on the linear relationship, it is better to use polynomial algorithms because it allows for a certain amount of curvature, it will be more accurate\nUse Thin Plate Spline algorithms to introduce the local deformations\n\n\n\n4.1.2 Atmospheric correction\nWe need to do the atmospheric correction to reduce the effect from path radiance and the haze created by absorption and scattering to get more accurate image\nThe methods to do the atmospheric correction:\n\nDark object subtraction (DOS), search the darkest value of image and subtract that from each pixel\nPsuedo-invariant features (PIFs) use the linear function to adjust the image\nACORN, FLAASH, QUAC, ATCOR\n\n\n\n4.1.3 Orthorectification correction\nThe aim of orthorectification correction:\n\nProvide the coordinates to an image\nRemove the distortions, make pixel viewed at straight down\n\nThe methods to do the orthorectification correction:\n\nConsider the solar zenith angle and solar azimuth angle to do the cosine correction\nThe software we can use QGIS, R packages like RStoolbox\n\n\n\n4.1.4 Radiometric calibration\nThe aim of radiometric calibration:\n\nConvert the digital number sensors captured from the image brightness (without units) to spectral radiance (with units)\n\nMethods to do the radiometric calbration:\n\nUse converting function"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "4  Week3: Corrections",
    "section": "4.2 Application",
    "text": "4.2 Application\n\n4.2.1 DOS and radiance\nI used the remote sensing image (LC08_L1TP_119038_20230104_20230111_02_T1.txt downloaded from USGS EarthExplorer) to calculate the pixel value of surface reflections generated from scattering by DOS:\ninstall.packages(\"rgdal\")\ninstall.packages(\"RStoolbox\")\nlibrary(terra)\nlibrary(raster)\nlibrary(RStoolbox)\nlibrary(tidyverse)\nlibrary(fs)\nlibrary(rgdal)\n\n## Import meta-data and bands based on MTL file\nmtlFile  <- (\"D:\\\\Remote Sensing\\\\week3\\\\LC08_L1TP_119038_20230104_20230111_02_T1\\\\LC08_L1TP_119038_20230104_20230111_02_T1_MTL.txt\")\n\nmetaData <- readMeta(mtlFile)\nlsatMeta  <- stackMeta(metaData)\n\n# surface reflection with DOS\nl8_boa_ref <- radCor(lsatMeta, metaData, method = \"dos\")\n\n# write to local dos\nterra::writeRaster(l8_boa_ref, datatype=\"FLT4S\", filename = \"D:\\\\Remote Sensing\\\\week3\\\\LC08_L1TP_119038_20230104_20230111_02_T1\\\\l8_boa_ref.tif\", format = \"GTiff\", overwrite=TRUE)\n\n# Radiance \nlsat_rad <- radCor(lsatMeta, metaData = metaData, method = \"rad\")\n\nterra::writeRaster(lsat_rad, datatype=\"FLT4S\", filename = \"D:\\\\Remote Sensing\\\\week3\\\\LC08_L1TP_119038_20230104_20230111_02_T1\\\\lsat_rad.tif\", format = \"GTiff\", overwrite=TRUE)\n\n\n\nl8_boa_ref\n\n\nConclusion:\nThere are several methods to execute the atmosphereic corrections (from digital number to reflectance), two typical examples are DOS and converting radiance to reflectance. In this case, the difference between radiance to reflectance and DOS correction is not significant and both can be corrected accurately. Actually, When the atmosphere is thinner or when the weather is good, the influence of the atmosphere on the ground radiation is less, the TOA and BOA are close to each other, a small part of the light reaches the sensor through the path radiance, so the less dark object needs to be substracted, the effect is close to the radiance. On the contrary, the more pixels need to be corrected the more obvious the effect of the corrected image is compared to the pre-correction image.\n# hazeDN\n\nhazeDN <- RStoolbox::estimateHaze(lsatMeta, hazeBands = 2:4, darkProp = 0.01, plot = TRUE)\n\nlsat_sref <- radCor(lsatMeta, metaData = metaData, method = \"dos\", \n                    hazeValues = hazeDN, hazeBands = 2:4)\n\nterra::writeRaster(lsat_sref, datatype=\"FLT4S\", filename = \"D:\\\\Remote Sensing\\\\week3\\\\LC08_L1TP_119038_20230104_20230111_02_T1\\\\lsat_sref.tif\", format = \"GTiff\", overwrite=TRUE)\n\n\n\nresult of hazeDN (3 Bands)\n\n\n\n\n4.2.2 Merging imagery\nLandsat8, Landsat9 and data preparation\n# List your raster files excluding band 8 using the patter argument\nlistlandsat_8<-dir_info(\"D:\\\\Remote Sensing\\\\week3\\\\LC08_L2SP_119038_20230104_20230111_02_T1\")%>%\n  dplyr::filter(str_detect(path, \"[B123456790].TIF\")) %>%\n  dplyr::select(path)%>%\n  pull()%>%\n  as.character()%>%\n  # Load our raster layers into a stack\n  terra::rast()\n\n# List your raster files excluding band 8 using the patter argument\nlistlandsat_9<-dir_info(\n\"D:\\\\Remote Sensing\\\\week3\\\\LC08_L2SP_119038_20230104_20230111_02_T1\"\n)%>%\n  dplyr::filter(str_detect(path, \"[1B23456790].TIF\")) %>%\n  dplyr::select(path)%>%\n  pull()%>%\n  as.character()%>%\n  # Load our raster layers into a stack\n  terra::rast()\n\n# data preparation\nm1 <- terra::mosaic(listlandsat_8, listlandsat_9, fun=\"mean\")\n\n\n4.2.3 Enhancement\nCalculate the NDVI (Normalized Difference Vegetation Index)\nm1_NDVI <- (m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B5 - m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B4) / (m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B5 + m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B4)\n\nm1_NDVI %>%\n  plot(.)\n\n\n\nresult of m1_NDVI\n\n\nSet m1_NDVI is not greater than 0.2\nveg <- m1_NDVI %>%\n  terra::classify(., cbind(-Inf, 0.2, NA))\n\nveg %>%\n  plot(.)\nThe highlight area of healthy vegetation:  From this map, the vegetation in the Taihu Lake basin is more concentrated to the west of the lake, where the most vegetation is found and where there is less population, while the area north of the lake to the south of the Yangtze River is less vegetated due to the high level of urbanisation, while the area north of the Yangtze River is relatively more vegetated.\nCalculate the NDMI (Normalized Difference Moisture Index) Use band 5 and band 6 on the occasion of Landsat8:\n\\(NDMI = (Band5 - Band6) / (Band5 + Band6)\\)\nm1_NDMI <- (m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B5 - m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B6) / (m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B5 + m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B6)\n\nm1_NDMI %>%\n  plot(.)\n\n\n\n\nresult of m1_NDMI\n\n\nmoi <- m1_NDMI %>%\n  terra::classify(., cbind(-Inf, 0.05, NA))\n\nmoi %>%\n  plot(.)\n ### Filtering\n# for a 3 by 3 filter on Band4\nm1_filter <- terra::focal(m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B4, w=matrix(nrow=3,ncol=3))\n\n\n4.2.4 Texture analysis\nGenerate the glcm.red and glcm.nir from Band4 and Band5, see the result under different statistical indicators\ninstall.packages(\"glcm\")\n\n\nlibrary(glcm)\nlibrary(raster)\n\n# band4 red, band5 NIR\n\nband4_raster <- raster::raster(m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B4)\nband5_raster <- raster::raster(m1$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B5)\n\nglcm.red <- glcm(band4_raster,\n                   window = c(7, 7),\n                   #shift=list(c(0,1), c(1,1), c(1,0), c(1,-1)), \n                   statistics = c(\"mean\",\n                                  \"variance\",\n                                  \"homogeneity\",\n                                  \"contrast\",\n                                  \"entropy\", \n                                  \"dissimilarity\",\n                                  \"second_moment\", \n                                  \"correlation\"))\n\n\nglcm.nir <- glcm(band5_raster,\n                   window = c(7, 7),\n                   #shift=list(c(0,1), c(1,1), c(1,0), c(1,-1)), \n                   statistics = c(\"mean\",\n                                  \"variance\",\n                                  \"homogeneity\",\n                                  \"contrast\",\n                                  \"entropy\", \n                                  \"dissimilarity\",\n                                  \"second_moment\", \n                                  \"correlation\"))\n\n\n\nplot(glcm.red)\n\n\n\nresult of glcm.red\n\n\nplot(glcm.nir)\n\n\n\nresult of glcm_nir\n\n\n\n\n4.2.5 Data fusion and PCA\n# for the next step of PCA we need to keep this in a raster format\n\n# m1_raster, glcm.red\nm1_raster <- stack(m1)\nFuse <- stack(m1_raster, glcm.red)\n\nFuse_3_bands <- stack(Fuse$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B4, Fuse$LC08_L2SP_119038_20230104_20230111_02_T1_SR_B5, Fuse$glcm_homogeneity)\n\nscale_fuse <- scale(Fuse_3_bands)\n\n# m1_raster, glcm.red\npca <- rasterPCA(Fuse, nSamples =100, spca = TRUE)\n\nsummary(pca$model)\n\n\n\nresult of pca (m1_raster, glcm.red)\n\n\nIt can be seen that in my study area, the component 1 accounts for 54.20%, and the summary of component 1 to component 3 accounts for over 90%, component 1 can explain the 54.2% data from entire dataset\nplot(pca$map)\n\n\n\nplot of PCA each component (m1_raster, glcm.red)\n\n\n# glcm.red, glcm.nir\nFuse <- scale(stack(glcm.red, glcm.nir))\n\npca <- rasterPCA(Fuse, nSamples = 100, spca = TRUE)\n                 \nsummary(pca$model)\n\n\n\nresult of pca (glcm.red, glcm.nir)\n\n\nThe component 1 of glcm.red and glcm.nir is 36.63%, the result is not so good\nplot(pca$map)"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "4  Week3: Corrections",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nIn this week, I learned the knowledge about the corrections, and the methods about corrections, the distortion of the images from remote sensing is mainly due to the presence of sensor observations in terms of declination, topography, wind and so on. Their correction uses statistical knowledge and principles (such as PCA, linear regression) as well as knowledge of spatial geometry.\nI think it is useful for the further study and work, for example, correcting the satellite image to satisfy people’s demand."
  }
]